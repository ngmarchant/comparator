% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FuzzyTokenSet.R
\name{FuzzyTokenSet}
\alias{FuzzyTokenSet}
\title{Fuzzy Token Set Distance}
\usage{
FuzzyTokenSet(
  inner_measure = Levenshtein(normalize = TRUE),
  separator = "\\\\s+",
  agg_function = base::mean,
  deletion = 1,
  insertion = 1,
  substitution = 1
)
}
\arguments{
\item{inner_measure}{inner string distance measure of class
\code{\linkS4class{StringMeasure}}. Defaults to normalized \code{\link{Levenshtein}} distance.}

\item{separator}{separator for tokens/words. Defaults to whitespace.}

\item{agg_function}{function used to aggregate the costs of the optimal
operations. Defaults to \code{\link[base:mean]{base::mean}}.}

\item{deletion}{positive weight associated with deletion of a token.
Defaults to unit cost.}

\item{insertion}{positive weight associated insertion of a token.
Defaults to unit cost.}

\item{substitution}{positive weight associated with substitution of a
token. Defaults to unit cost.}
}
\description{
This hybrid token-character measure is suitable for comparing a pair of
multi-token (multi-word) strings \eqn{x} and \eqn{y}. It measures the
minimum cost of transforming the token set representation of \eqn{x} into
the token set representation of \eqn{y} using single-token operations
(insertions, deletions and substitutions). The cost of the operations are
determined using an internal user-specified distance measure.
}
\details{
This measure compares the input strings \eqn{x} and \eqn{y} using a token
set representation. A token set is an unordered enumeration of tokens,
which may include duplicates. For example, the token set representation
of the string "Paw Paw Illinois" is {"Illinois", "Paw", "Paw"}. After
mapping \eqn{x} and \eqn{y} to token sets, the minimum cost of transforming
\eqn{x} into \eqn{y} is computed based on three single-token operations:
insertions, deletions and substitutions. The costs of the operations are
specified as follows:
\itemize{
\item cost of deleting a token \eqn{a} from \eqn{x}: \eqn{w_d \times \mathrm{inner}(a, "")}{w_d * inner(a, "")}
\item cost of inserting a token \eqn{b} in \eqn{y}: \eqn{w_i \times \mathrm{inner}("", b)}{w_i * inner("", b)}
\item cost of substituting a token \eqn{a} in \eqn{x} for a token \eqn{b}
in \eqn{y}: \eqn{w_s \times \mathrm{inner}(a, b)}{w_s * inner(a, b)}
}

where \eqn{\mathrm{inner}}{inner} is a user-specified internal string
measure and \eqn{w_d, w_i, w_s} are user-specified weights, referred to as
\code{deletion}, \code{insertion} and \code{substitution} in the parameter list. By
default, the mean cost of the optimal (cost-minimizing) set of operations is
returned as a measure of the distance between \eqn{x} and \eqn{y}. Other
methods of aggregating the costs are supported by specifying a non-default
\code{agg_function}.

The optimisation problem---of finding the minimum total cost under the
allowed operations---is solved exactly using a linear sum assignment
solver.
}
\note{
This measure is qualitatively similar to the \code{\link{MongeElkan}} measure,
however it is arguably more principled, since it is formulated as a
cost minimization problem. It also offers more control over the costs
of missing tokens (by varying the \code{deletion} and \code{insertion} weights).
This is useful for comparing full names, where dropping a name (e.g.
middle name) should not be severely penalized.
}
\examples{
## Compare names with heterogenous representations
x <- "The University of California - San Diego"
y <- "Univ. Calif. San Diego"
FuzzyTokenSet()(x, y)

# Reduce the cost associated with missing words
FuzzyTokenSet(deletion = 0.5, insertion = 0.5)(x, y)

## Compare full names, recognizing that it is common to omit names
x <- "JOSE ELIAS TEJADA BASQUES"
y <- "JOSE BASQUES"
FuzzyTokenSet(deletion = 0.5, insertion = 0.5)(x, y)

}
